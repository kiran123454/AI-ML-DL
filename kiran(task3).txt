question 1:  
# MSE (Mean Squared Error) problem solution 
import numpy as np

# Actual and predicted values
y_true = np.array([7, -0.8, 4, 3.5])
y_pred = np.array([2, 0.0, 2.4, 8.0])

# Compute MSE
mse = np.mean((y_true - y_pred) ** 2)
print("MSE:", mse)

# MSE (Mean Squared Error) problem solution 
import numpy as np
​
# Actual and predicted values
y_true = np.array([7, -0.8, 4, 3.5])
y_pred = np.array([2, 0.0, 2.4, 8.0])
​
# Compute MSE
mse = np.mean((y_true - y_pred) ** 2)
print("MSE:", mse)
​
MSE: 12.1125


question 2:
# RMSE ( Root Mean Squared Error) problem solution
# RMSE ( Root Mean Squared Error) problem solution
import numpy as np
​
# Actual and predicted values
y_true = np.array([7, -0.8, 4, 3.5])
y_pred = np.array([2, 0.0, 2.4, 8.0])
​
# Compute RMSE
rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))
print("RMSE:", rmse)
​
RMSE: 3.480301711058971


question 3:
# Cosine similraity problem solution
import numpy as np

# Define vectors
A = np.array([1.7, 4.6, 3])
B = np.array([2.4, 5.5, 6])

# Compute Cosine Similarity
cosine_sim = np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))

print("Cosine Similarity:", cosine_sim)

Cosine Similarity: 0.9712094936510126


question 4:
# solution for linear regression problem 
import numpy as np

# Sample data
X = np.array([1.3, 2.3, 3.3, 4.3, 5.3])  # Independent variable
y = np.array([2.7, 3.7, 5.7, 6.7, 8.7])  # Dependent variable

# Compute coefficients using least squares formula
X_mean = np.mean(X)
y_mean = np.mean(y)

b1 = np.sum((X - X_mean) * (y - y_mean)) / np.sum((X - X_mean) ** 2)  # Slope
b0 = y_mean - (b1 * X_mean)  # Intercept

# Make predictions
y_pred = b0 + b1 * X

print(f"Intercept (b0): {b0}")
print(f"Slope (b1): {b1}")
print(f"Predicted values: {y_pred}")

Intercept (b0): 0.5500000000000016
Slope (b1): 1.4999999999999996
Predicted values: [2.5 4.  5.5 7.  8.5]


question 5:
# solution for softmax function 
import numpy as np

def softmax(x):
    exp_x = np.exp(x - np.max(x))  # Subtracting max for numerical stability
    return exp_x / np.sum(exp_x)

# Example input (logits)
logits = np.array([2.6, 1.5, 0.1])

# Compute Softmax
probabilities = softmax(logits)
print("Softmax Output:", probabilities)

Softmax Output: [0.70673572 0.23525188 0.0580124 ]